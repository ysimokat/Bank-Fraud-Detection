{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hybrid Ensemble System for Fraud Detection\n",
    "\n",
    "## Tutorial 8: Advanced Ensemble Techniques and Meta-Learning\n",
    "\n",
    "In this tutorial, you'll learn how to build sophisticated ensemble systems that combine multiple approaches:\n",
    "- **Context-Aware Ensembles**: Adapt to transaction characteristics\n",
    "- **Meta-Learning (Stacking)**: Learn from base model predictions\n",
    "- **Dynamic Model Selection**: Choose optimal models for each prediction\n",
    "- **Hierarchical Ensembles**: Multi-level ensemble architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "\n",
    "By the end of this tutorial, you'll understand:\n",
    "\n",
    "1. **Advanced Ensemble Strategies**: Beyond simple voting and averaging\n",
    "2. **Meta-Learning**: Train models on model predictions\n",
    "3. **Context-Aware Systems**: Adapt behavior based on transaction context\n",
    "4. **Dynamic Model Selection**: Choose best models for each prediction\n",
    "5. **Hierarchical Ensembles**: Multi-level ensemble architectures\n",
    "6. **Feature Engineering**: Create meaningful features at multiple levels\n",
    "7. **Cross-Validation**: Proper validation to avoid overfitting\n",
    "8. **Performance Optimization**: Combine complementary strengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression, Ridge\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score,\n",
    "    confusion_matrix, classification_report, roc_curve, auc\n",
    ")\n",
    "import xgboost as xgb\n",
    "from scipy import stats\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for better visualizations\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Hybrid Ensemble System for Fraud Detection\")\n",
    "print(\"Advanced ensemble techniques and meta-learning tutorial\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Understanding Ensemble Diversity\n",
    "\n",
    "### The Power of Diversity\n",
    "\n",
    "Ensemble methods work best when individual models:\n",
    "- **Make different types of errors**: Complementary strengths\n",
    "- **Use different algorithms**: Diverse learning approaches\n",
    "- **Focus on different aspects**: Feature importance, decision boundaries\n",
    "- **Perform well in different contexts**: Time, amount, pattern types\n",
    "\n",
    "### Traditional vs Advanced Ensembles\n",
    "\n",
    "- **Traditional**: Simple voting, averaging, basic weighting\n",
    "- **Advanced**: Meta-learning, context-aware weighting, dynamic selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and prepare data\n",
    "df = pd.read_csv('creditcard.csv')\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Fraud rate: {df['Class'].mean()*100:.3f}%\")\n",
    "\n",
    "# Prepare features and target\n",
    "X = df.drop('Class', axis=1)\n",
    "y = df['Class']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"\\nTraining set: {X_train.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")\n",
    "print(f\"Training fraud rate: {y_train.mean()*100:.3f}%\")\n",
    "print(f\"Test fraud rate: {y_test.mean()*100:.3f}%\")\n",
    "\n",
    "# Visualize ensemble diversity concept\n",
    "def visualize_ensemble_diversity():\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # Traditional ensemble\n",
    "    axes[0, 0].text(0.5, 0.9, 'Traditional Ensemble', ha='center', fontsize=14, fontweight='bold')\n",
    "    axes[0, 0].text(0.5, 0.7, 'Simple Voting/Averaging', ha='center', fontsize=12)\n",
    "    axes[0, 0].text(0.5, 0.5, 'Model 1 + Model 2 + Model 3', ha='center', fontsize=11, family='monospace')\n",
    "    axes[0, 0].text(0.5, 0.3, 'Fixed weights', ha='center', fontsize=10, style='italic')\n",
    "    axes[0, 0].text(0.5, 0.1, 'Same treatment for all predictions', ha='center', fontsize=10, style='italic')\n",
    "    axes[0, 0].set_xlim(0, 1)\n",
    "    axes[0, 0].set_ylim(0, 1)\n",
    "    axes[0, 0].axis('off')\n",
    "    \n",
    "    # Context-aware ensemble\n",
    "    axes[0, 1].text(0.5, 0.9, 'Context-Aware Ensemble', ha='center', fontsize=14, fontweight='bold')\n",
    "    axes[0, 1].text(0.5, 0.7, 'Adaptive Weighting', ha='center', fontsize=12)\n",
    "    axes[0, 1].text(0.5, 0.5, 'w₁(context) × Model 1 + ...', ha='center', fontsize=11, family='monospace')\n",
    "    axes[0, 1].text(0.5, 0.3, 'Context-specific weights', ha='center', fontsize=10, style='italic')\n",
    "    axes[0, 1].text(0.5, 0.1, 'Adapts to transaction characteristics', ha='center', fontsize=10, style='italic')\n",
    "    axes[0, 1].set_xlim(0, 1)\n",
    "    axes[0, 1].set_ylim(0, 1)\n",
    "    axes[0, 1].axis('off')\n",
    "    \n",
    "    # Meta-learning ensemble\n",
    "    axes[1, 0].text(0.5, 0.9, 'Meta-Learning Ensemble', ha='center', fontsize=14, fontweight='bold')\n",
    "    axes[1, 0].text(0.5, 0.7, 'Stacking', ha='center', fontsize=12)\n",
    "    axes[1, 0].text(0.5, 0.5, 'Meta-Model(pred₁, pred₂, pred₃)', ha='center', fontsize=11, family='monospace')\n",
    "    axes[1, 0].text(0.5, 0.3, 'Learns from predictions', ha='center', fontsize=10, style='italic')\n",
    "    axes[1, 0].text(0.5, 0.1, 'Optimal combination strategy', ha='center', fontsize=10, style='italic')\n",
    "    axes[1, 0].set_xlim(0, 1)\n",
    "    axes[1, 0].set_ylim(0, 1)\n",
    "    axes[1, 0].axis('off')\n",
    "    \n",
    "    # Dynamic selection\n",
    "    axes[1, 1].text(0.5, 0.9, 'Dynamic Selection', ha='center', fontsize=14, fontweight='bold')\n",
    "    axes[1, 1].text(0.5, 0.7, 'Instance-based Selection', ha='center', fontsize=12)\n",
    "    axes[1, 1].text(0.5, 0.5, 'Select best models per instance', ha='center', fontsize=11, family='monospace')\n",
    "    axes[1, 1].text(0.5, 0.3, 'Confidence-weighted', ha='center', fontsize=10, style='italic')\n",
    "    axes[1, 1].text(0.5, 0.1, 'Optimal model per prediction', ha='center', fontsize=10, style='italic')\n",
    "    axes[1, 1].set_xlim(0, 1)\n",
    "    axes[1, 1].set_ylim(0, 1)\n",
    "    axes[1, 1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Key Advantages of Advanced Ensembles:\")\n",
    "    print(\"1. Context-Aware: Adapt to transaction characteristics\")\n",
    "    print(\"2. Meta-Learning: Learn optimal combination strategies\")\n",
    "    print(\"3. Dynamic: Choose best models for each prediction\")\n",
    "    print(\"4. Hierarchical: Multi-level ensemble architectures\")\n",
    "\n",
    "visualize_ensemble_diversity()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Context-Aware Ensemble\n",
    "\n",
    "### Understanding Context in Fraud Detection\n",
    "\n",
    "Different transaction contexts require different model emphasis:\n",
    "- **Time of Day**: Different fraud patterns during business hours vs night\n",
    "- **Transaction Amount**: High-value vs low-value transaction patterns\n",
    "- **Feature Patterns**: Statistical characteristics of V1-V28 features\n",
    "- **Historical Performance**: Which models work best in which contexts\n",
    "\n",
    "### Context-Aware Weighting Strategy\n",
    "\n",
    "1. **Extract Context Features**: Time, amount, statistical measures\n",
    "2. **Cluster Similar Contexts**: Group transactions with similar characteristics\n",
    "3. **Learn Context-Specific Weights**: Optimize weights for each context cluster\n",
    "4. **Apply Dynamic Weighting**: Use context to determine model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContextAwareEnsemble:\n",
    "    \"\"\"\n",
    "    Context-aware ensemble that adapts model weights based on transaction context.\n",
    "    \n",
    "    Key features:\n",
    "    - Extracts contextual features (time, amount, statistical measures)\n",
    "    - Uses clustering to identify similar transaction contexts\n",
    "    - Learns optimal model weights for each context\n",
    "    - Dynamically applies context-specific weights\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, base_models, n_context_clusters=5):\n",
    "        \"\"\"\n",
    "        Initialize context-aware ensemble.\n",
    "        \n",
    "        Args:\n",
    "            base_models: Dictionary of base models\n",
    "            n_context_clusters: Number of context clusters\n",
    "        \"\"\"\n",
    "        self.base_models = base_models\n",
    "        self.n_context_clusters = n_context_clusters\n",
    "        self.model_names = list(base_models.keys())\n",
    "        self.n_models = len(base_models)\n",
    "        \n",
    "        # Context analysis components\n",
    "        self.context_clusterer = KMeans(n_clusters=n_context_clusters, random_state=42)\n",
    "        self.context_weights = {}  # weights for each context cluster\n",
    "        self.context_scaler = StandardScaler()\n",
    "        \n",
    "        # Performance tracking\n",
    "        self.context_performance = defaultdict(lambda: defaultdict(list))\n",
    "        \n",
    "    def _extract_context_features(self, X):\n",
    "        \"\"\"\n",
    "        Extract contextual features from transactions.\n",
    "        \n",
    "        Args:\n",
    "            X: Transaction features\n",
    "        \n",
    "        Returns:\n",
    "            Context feature matrix\n",
    "        \"\"\"\n",
    "        context_features = []\n",
    "        \n",
    "        for i in range(len(X)):\n",
    "            if isinstance(X, pd.DataFrame):\n",
    "                row = X.iloc[i]\n",
    "            else:\n",
    "                row = X[i]\n",
    "            \n",
    "            # Time-based features\n",
    "            if 'Time' in X.columns if isinstance(X, pd.DataFrame) else len(row) > 0:\n",
    "                time_val = row.iloc[0] if isinstance(X, pd.DataFrame) else row[0]\n",
    "                hour_of_day = (time_val % (24 * 3600)) // 3600\n",
    "                is_weekend = ((time_val // (24 * 3600)) % 7) >= 5\n",
    "            else:\n",
    "                hour_of_day = 12  # Default\n",
    "                is_weekend = False\n",
    "            \n",
    "            # Amount-based features\n",
    "            if 'Amount' in X.columns if isinstance(X, pd.DataFrame) else len(row) > 28:\n",
    "                amount = row['Amount'] if isinstance(X, pd.DataFrame) else row[28]\n",
    "                amount_bin = self._get_amount_bin(amount)\n",
    "                log_amount = np.log1p(amount)\n",
    "            else:\n",
    "                amount = 0\n",
    "                amount_bin = 0\n",
    "                log_amount = 0\n",
    "            \n",
    "            # Statistical features from V1-V28\n",
    "            if isinstance(X, pd.DataFrame):\n",
    "                v_features = row[[f'V{i}' for i in range(1, 29)]].values\n",
    "            else:\n",
    "                v_features = row[1:29]  # Assuming V1-V28 are columns 1-28\n",
    "            \n",
    "            v_mean = np.mean(v_features)\n",
    "            v_std = np.std(v_features)\n",
    "            v_skew = stats.skew(v_features)\n",
    "            v_kurtosis = stats.kurtosis(v_features)\n",
    "            v_max = np.max(v_features)\n",
    "            v_min = np.min(v_features)\n",
    "            \n",
    "            # Combine all context features\n",
    "            context_feature = [\n",
    "                hour_of_day,\n",
    "                float(is_weekend),\n",
    "                amount_bin,\n",
    "                log_amount,\n",
    "                v_mean,\n",
    "                v_std,\n",
    "                v_skew,\n",
    "                v_kurtosis,\n",
    "                v_max,\n",
    "                v_min\n",
    "            ]\n",
    "            \n",
    "            context_features.append(context_feature)\n",
    "        \n",
    "        return np.array(context_features)\n",
    "    \n",
    "    def _get_amount_bin(self, amount):\n",
    "        \"\"\"\n",
    "        Categorize transaction amount into bins.\n",
    "        \n",
    "        Args:\n",
    "            amount: Transaction amount\n",
    "        \n",
    "        Returns:\n",
    "            Amount bin (0-4)\n",
    "        \"\"\"\n",
    "        if amount <= 10:\n",
    "            return 0  # Very low\n",
    "        elif amount <= 50:\n",
    "            return 1  # Low\n",
    "        elif amount <= 200:\n",
    "            return 2  # Medium\n",
    "        elif amount <= 1000:\n",
    "            return 3  # High\n",
    "        else:\n",
    "            return 4  # Very high\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit the context-aware ensemble.\n",
    "        \n",
    "        Args:\n",
    "            X: Training features\n",
    "            y: Training labels\n",
    "        \"\"\"\n",
    "        print(\"Training context-aware ensemble...\")\n",
    "        \n",
    "        # Train base models\n",
    "        for name, model in self.base_models.items():\n",
    "            print(f\"  Training {name}...\")\n",
    "            model.fit(X, y)\n",
    "        \n",
    "        # Extract context features\n",
    "        context_features = self._extract_context_features(X)\n",
    "        \n",
    "        # Scale context features\n",
    "        context_features_scaled = self.context_scaler.fit_transform(context_features)\n",
    "        \n",
    "        # Cluster contexts\n",
    "        context_clusters = self.context_clusterer.fit_predict(context_features_scaled)\n",
    "        \n",
    "        # Learn context-specific weights\n",
    "        self._learn_context_weights(X, y, context_clusters)\n",
    "        \n",
    "        print(f\"  Identified {self.n_context_clusters} context clusters\")\n",
    "        print(f\"  Learned context-specific weights for {self.n_models} models\")\n",
    "    \n",
    "    def _learn_context_weights(self, X, y, context_clusters):\n",
    "        \"\"\"\n",
    "        Learn optimal model weights for each context cluster.\n",
    "        \n",
    "        Args:\n",
    "            X: Training features\n",
    "            y: Training labels\n",
    "            context_clusters: Cluster assignments for each sample\n",
    "        \"\"\"\n",
    "        # Get predictions from all base models\n",
    "        base_predictions = np.zeros((len(X), self.n_models))\n",
    "        \n",
    "        for i, (name, model) in enumerate(self.base_models.items()):\n",
    "            if hasattr(model, 'predict_proba'):\n",
    "                base_predictions[:, i] = model.predict_proba(X)[:, 1]\n",
    "            else:\n",
    "                base_predictions[:, i] = model.decision_function(X)\n",
    "        \n",
    "        # Learn weights for each context cluster\n",
    "        for cluster_id in range(self.n_context_clusters):\n",
    "            cluster_mask = context_clusters == cluster_id\n",
    "            \n",
    "            if np.sum(cluster_mask) < 10:  # Skip clusters with too few samples\n",
    "                self.context_weights[cluster_id] = np.ones(self.n_models) / self.n_models\n",
    "                continue\n",
    "            \n",
    "            cluster_predictions = base_predictions[cluster_mask]\n",
    "            cluster_labels = y.iloc[cluster_mask] if isinstance(y, pd.Series) else y[cluster_mask]\n",
    "            \n",
    "            # Use Ridge regression to learn optimal weights\n",
    "            ridge = Ridge(alpha=1.0, fit_intercept=False, positive=True)\n",
    "            ridge.fit(cluster_predictions, cluster_labels)\n",
    "            \n",
    "            # Normalize weights to sum to 1\n",
    "            weights = ridge.coef_\n",
    "            weights = np.maximum(weights, 0)  # Ensure non-negative\n",
    "            weights = weights / np.sum(weights) if np.sum(weights) > 0 else np.ones(self.n_models) / self.n_models\n",
    "            \n",
    "            self.context_weights[cluster_id] = weights\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        Make predictions using context-aware weighting.\n",
    "        \n",
    "        Args:\n",
    "            X: Features\n",
    "        \n",
    "        Returns:\n",
    "            Prediction probabilities\n",
    "        \"\"\"\n",
    "        # Extract context features\n",
    "        context_features = self._extract_context_features(X)\n",
    "        context_features_scaled = self.context_scaler.transform(context_features)\n",
    "        \n",
    "        # Assign context clusters\n",
    "        context_clusters = self.context_clusterer.predict(context_features_scaled)\n",
    "        \n",
    "        # Get base model predictions\n",
    "        base_predictions = np.zeros((len(X), self.n_models))\n",
    "        \n",
    "        for i, (name, model) in enumerate(self.base_models.items()):\n",
    "            if hasattr(model, 'predict_proba'):\n",
    "                base_predictions[:, i] = model.predict_proba(X)[:, 1]\n",
    "            else:\n",
    "                # Convert decision function to probabilities\n",
    "                decisions = model.decision_function(X)\n",
    "                base_predictions[:, i] = 1 / (1 + np.exp(-decisions))\n",
    "        \n",
    "        # Apply context-specific weights\n",
    "        ensemble_predictions = np.zeros(len(X))\n",
    "        \n",
    "        for i in range(len(X)):\n",
    "            cluster_id = context_clusters[i]\n",
    "            weights = self.context_weights.get(cluster_id, np.ones(self.n_models) / self.n_models)\n",
    "            ensemble_predictions[i] = np.dot(base_predictions[i], weights)\n",
    "        \n",
    "        # Convert to probability format\n",
    "        prob_positive = ensemble_predictions\n",
    "        prob_negative = 1 - prob_positive\n",
    "        \n",
    "        return np.column_stack([prob_negative, prob_positive])\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Make binary predictions.\"\"\"\n",
    "        probabilities = self.predict_proba(X)\n",
    "        return (probabilities[:, 1] > 0.5).astype(int)\n",
    "    \n",
    "    def get_context_analysis(self):\n",
    "        \"\"\"\n",
    "        Get analysis of context clusters and their weights.\n",
    "        \n",
    "        Returns:\n",
    "            Dictionary with context analysis\n",
    "        \"\"\"\n",
    "        analysis = {\n",
    "            'n_clusters': self.n_context_clusters,\n",
    "            'cluster_weights': self.context_weights,\n",
    "            'model_names': self.model_names\n",
    "        }\n",
    "        \n",
    "        return analysis\n",
    "\n",
    "# Create and test context-aware ensemble\n",
    "print(\"Creating Context-Aware Ensemble...\")\n",
    "\n",
    "# Define base models\n",
    "base_models = {\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced'),\n",
    "    'XGBoost': xgb.XGBClassifier(n_estimators=100, random_state=42, scale_pos_weight=10, eval_metric='logloss'),\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, class_weight='balanced', max_iter=1000),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "# Create context-aware ensemble\n",
    "context_ensemble = ContextAwareEnsemble(base_models, n_context_clusters=5)\n",
    "\n",
    "# Train ensemble\n",
    "context_ensemble.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "context_predictions = context_ensemble.predict(X_test)\n",
    "context_probabilities = context_ensemble.predict_proba(X_test)\n",
    "\n",
    "# Evaluate performance\n",
    "context_accuracy = accuracy_score(y_test, context_predictions)\n",
    "context_precision = precision_score(y_test, context_predictions)\n",
    "context_recall = recall_score(y_test, context_predictions)\n",
    "context_f1 = f1_score(y_test, context_predictions)\n",
    "context_roc_auc = roc_auc_score(y_test, context_probabilities[:, 1])\n",
    "\n",
    "print(f\"\\nContext-Aware Ensemble Performance:\")\n",
    "print(f\"Accuracy: {context_accuracy:.4f}\")\n",
    "print(f\"Precision: {context_precision:.4f}\")\n",
    "print(f\"Recall: {context_recall:.4f}\")\n",
    "print(f\"F1-Score: {context_f1:.4f}\")\n",
    "print(f\"ROC-AUC: {context_roc_auc:.4f}\")\n",
    "\n",
    "# Analyze context clusters\n",
    "context_analysis = context_ensemble.get_context_analysis()\n",
    "print(f\"\\nContext Analysis:\")\n",
    "print(f\"Number of clusters: {context_analysis['n_clusters']}\")\n",
    "print(f\"\\nCluster weights:\")\n",
    "for cluster_id, weights in context_analysis['cluster_weights'].items():\n",
    "    print(f\"  Cluster {cluster_id}:\")\n",
    "    for i, (model_name, weight) in enumerate(zip(context_analysis['model_names'], weights)):\n",
    "        print(f\"    {model_name}: {weight:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Meta-Learning Ensemble (Stacking)\n",
    "\n",
    "### Understanding Meta-Learning\n",
    "\n",
    "Meta-learning in ensembles involves:\n",
    "1. **Level 0**: Train base models on original data\n",
    "2. **Level 1**: Use base model predictions as features for meta-model\n",
    "3. **Cross-Validation**: Avoid overfitting in meta-feature generation\n",
    "4. **Feature Engineering**: Create meaningful meta-features\n",
    "\n",
    "### Advanced Meta-Features\n",
    "\n",
    "Beyond simple predictions, we can create:\n",
    "- **Agreement measures**: How much models agree/disagree\n",
    "- **Confidence measures**: Model uncertainty indicators\n",
    "- **Ranking features**: Relative model performance\n",
    "- **Statistical features**: Mean, std, min, max of predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetaLearnerEnsemble:\n",
    "    \"\"\"\n",
    "    Meta-learning ensemble using stacking with advanced feature engineering.\n",
    "    \n",
    "    Key features:\n",
    "    - Cross-validation for meta-feature generation\n",
    "    - Advanced meta-feature engineering\n",
    "    - Multiple meta-learners\n",
    "    - Ensemble of meta-learners\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, base_models, meta_models=None, cv_folds=5):\n",
    "        \"\"\"\n",
    "        Initialize meta-learning ensemble.\n",
    "        \n",
    "        Args:\n",
    "            base_models: Dictionary of base models\n",
    "            meta_models: Dictionary of meta-learners\n",
    "            cv_folds: Cross-validation folds for meta-feature generation\n",
    "        \"\"\"\n",
    "        self.base_models = base_models\n",
    "        self.cv_folds = cv_folds\n",
    "        self.model_names = list(base_models.keys())\n",
    "        self.n_models = len(base_models)\n",
    "        \n",
    "        # Default meta-learners if not provided\n",
    "        if meta_models is None:\n",
    "            self.meta_models = {\n",
    "                'Meta_Logistic': LogisticRegression(random_state=42, class_weight='balanced'),\n",
    "                'Meta_RF': RandomForestClassifier(n_estimators=50, random_state=42, class_weight='balanced'),\n",
    "                'Meta_XGB': xgb.XGBClassifier(n_estimators=50, random_state=42, scale_pos_weight=10, eval_metric='logloss')\n",
    "            }\n",
    "        else:\n",
    "            self.meta_models = meta_models\n",
    "        \n",
    "        # Meta-ensemble for combining meta-learners\n",
    "        self.meta_ensemble = LogisticRegression(random_state=42, class_weight='balanced')\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit the meta-learning ensemble.\n",
    "        \n",
    "        Args:\n",
    "            X: Training features\n",
    "            y: Training labels\n",
    "        \"\"\"\n",
    "        print(\"Training meta-learning ensemble...\")\n",
    "        \n",
    "        # Train base models\n",
    "        for name, model in self.base_models.items():\n",
    "            print(f\"  Training base model: {name}\")\n",
    "            model.fit(X, y)\n",
    "        \n",
    "        # Generate meta-features using cross-validation\n",
    "        print(\"  Generating meta-features...\")\n",
    "        meta_features = self._generate_meta_features(X, y)\n",
    "        \n",
    "        # Engineer additional meta-features\n",
    "        print(\"  Engineering meta-features...\")\n",
    "        engineered_meta_features = self._engineer_meta_features(meta_features)\n",
    "        \n",
    "        # Train meta-learners\n",
    "        print(\"  Training meta-learners...\")\n",
    "        for name, meta_model in self.meta_models.items():\n",
    "            print(f\"    Training {name}\")\n",
    "            meta_model.fit(engineered_meta_features, y)\n",
    "        \n",
    "        # Generate meta-meta-features for final ensemble\n",
    "        meta_meta_features = np.zeros((len(X), len(self.meta_models)))\n",
    "        \n",
    "        # Use cross-validation to generate meta-meta-features\n",
    "        skf = StratifiedKFold(n_splits=self.cv_folds, shuffle=True, random_state=42)\n",
    "        \n",
    "        for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "            # Train meta-learners on fold\n",
    "            fold_meta_features = engineered_meta_features[train_idx]\n",
    "            fold_labels = y.iloc[train_idx] if isinstance(y, pd.Series) else y[train_idx]\n",
    "            \n",
    "            for i, (name, meta_model) in enumerate(self.meta_models.items()):\n",
    "                # Clone and train meta-model on fold\n",
    "                from sklearn.base import clone\n",
    "                fold_meta_model = clone(meta_model)\n",
    "                fold_meta_model.fit(fold_meta_features, fold_labels)\n",
    "                \n",
    "                # Predict on validation set\n",
    "                val_meta_features = engineered_meta_features[val_idx]\n",
    "                if hasattr(fold_meta_model, 'predict_proba'):\n",
    "                    meta_meta_features[val_idx, i] = fold_meta_model.predict_proba(val_meta_features)[:, 1]\n",
    "                else:\n",
    "                    decisions = fold_meta_model.decision_function(val_meta_features)\n",
    "                    meta_meta_features[val_idx, i] = 1 / (1 + np.exp(-decisions))\n",
    "        \n",
    "        # Train final meta-ensemble\n",
    "        print(\"  Training final meta-ensemble...\")\n",
    "        self.meta_ensemble.fit(meta_meta_features, y)\n",
    "        \n",
    "        print(f\"  Meta-learning ensemble trained with {self.n_models} base models and {len(self.meta_models)} meta-learners\")\n",
    "    \n",
    "    def _generate_meta_features(self, X, y):\n",
    "        \"\"\"\n",
    "        Generate meta-features using cross-validation.\n",
    "        \n",
    "        Args:\n",
    "            X: Training features\n",
    "            y: Training labels\n",
    "        \n",
    "        Returns:\n",
    "            Meta-features matrix\n",
    "        \"\"\"\n",
    "        meta_features = np.zeros((len(X), self.n_models))\n",
    "        \n",
    "        # Use stratified k-fold cross-validation\n",
    "        skf = StratifiedKFold(n_splits=self.cv_folds, shuffle=True, random_state=42)\n",
    "        \n",
    "        for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "            # Get fold data\n",
    "            if isinstance(X, pd.DataFrame):\n",
    "                X_fold_train, X_fold_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "            else:\n",
    "                X_fold_train, X_fold_val = X[train_idx], X[val_idx]\n",
    "            \n",
    "            y_fold_train = y.iloc[train_idx] if isinstance(y, pd.Series) else y[train_idx]\n",
    "            \n",
    "            # Train base models on fold and predict on validation\n",
    "            for i, (name, model) in enumerate(self.base_models.items()):\n",
    "                # Clone and train model on fold\n",
    "                from sklearn.base import clone\n",
    "                fold_model = clone(model)\n",
    "                fold_model.fit(X_fold_train, y_fold_train)\n",
    "                \n",
    "                # Predict on validation set\n",
    "                if hasattr(fold_model, 'predict_proba'):\n",
    "                    meta_features[val_idx, i] = fold_model.predict_proba(X_fold_val)[:, 1]\n",
    "                else:\n",
    "                    decisions = fold_model.decision_function(X_fold_val)\n",
    "                    meta_features[val_idx, i] = 1 / (1 + np.exp(-decisions))\n",
    "        \n",
    "        return meta_features\n",
    "    \n",
    "    def _engineer_meta_features(self, meta_features):\n",
    "        \"\"\"\n",
    "        Engineer additional meta-features from base predictions.\n",
    "        \n",
    "        Args:\n",
    "            meta_features: Base model predictions\n",
    "        \n",
    "        Returns:\n",
    "            Engineered meta-features\n",
    "        \"\"\"\n",
    "        n_samples = meta_features.shape[0]\n",
    "        \n",
    "        # Initialize feature list with original meta-features\n",
    "        features = [meta_features]\n",
    "        \n",
    "        # Statistical features\n",
    "        features.append(np.mean(meta_features, axis=1).reshape(-1, 1))  # Mean prediction\n",
    "        features.append(np.std(meta_features, axis=1).reshape(-1, 1))   # Std of predictions\n",
    "        features.append(np.min(meta_features, axis=1).reshape(-1, 1))   # Min prediction\n",
    "        features.append(np.max(meta_features, axis=1).reshape(-1, 1))   # Max prediction\n",
    "        \n",
    "        # Agreement features\n",
    "        binary_predictions = (meta_features > 0.5).astype(int)\n",
    "        agreement = np.mean(binary_predictions, axis=1).reshape(-1, 1)  # Fraction agreeing\n",
    "        features.append(agreement)\n",
    "        \n",
    "        # Disagreement features\n",
    "        disagreement = np.std(binary_predictions, axis=1).reshape(-1, 1)\n",
    "        features.append(disagreement)\n",
    "        \n",
    "        # Confidence features\n",
    "        confidence = 1 - np.std(meta_features, axis=1).reshape(-1, 1)  # Inverse of std\n",
    "        features.append(confidence)\n",
    "        \n",
    "        # Ranking features\n",
    "        ranks = np.argsort(np.argsort(meta_features, axis=1), axis=1)  # Rank of each prediction\n",
    "        features.append(ranks)\n",
    "        \n",
    "        # Pairwise differences\n",
    "        for i in range(self.n_models):\n",
    "            for j in range(i + 1, self.n_models):\n",
    "                diff = (meta_features[:, i] - meta_features[:, j]).reshape(-1, 1)\n",
    "                features.append(diff)\n",
    "        \n",
    "        # Combine all features\n",
    "        engineered_features = np.hstack(features)\n",
    "        \n",
    "        return engineered_features\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        Make predictions using meta-learning ensemble.\n",
    "        \n",
    "        Args:\n",
    "            X: Features\n",
    "        \n",
    "        Returns:\n",
    "            Prediction probabilities\n",
    "        \"\"\"\n",
    "        # Get base model predictions\n",
    "        base_predictions = np.zeros((len(X), self.n_models))\n",
    "        \n",
    "        for i, (name, model) in enumerate(self.base_models.items()):\n",
    "            if hasattr(model, 'predict_proba'):\n",
    "                base_predictions[:, i] = model.predict_proba(X)[:, 1]\n",
    "            else:\n",
    "                decisions = model.decision_function(X)\n",
    "                base_predictions[:, i] = 1 / (1 + np.exp(-decisions))\n",
    "        \n",
    "        # Engineer meta-features\n",
    "        engineered_meta_features = self._engineer_meta_features(base_predictions)\n",
    "        \n",
    "        # Get meta-learner predictions\n",
    "        meta_predictions = np.zeros((len(X), len(self.meta_models)))\n",
    "        \n",
    "        for i, (name, meta_model) in enumerate(self.meta_models.items()):\n",
    "            if hasattr(meta_model, 'predict_proba'):\n",
    "                meta_predictions[:, i] = meta_model.predict_proba(engineered_meta_features)[:, 1]\n",
    "            else:\n",
    "                decisions = meta_model.decision_function(engineered_meta_features)\n",
    "                meta_predictions[:, i] = 1 / (1 + np.exp(-decisions))\n",
    "        \n",
    "        # Final ensemble prediction\n",
    "        final_predictions = self.meta_ensemble.predict_proba(meta_predictions)\n",
    "        \n",
    "        return final_predictions\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Make binary predictions.\"\"\"\n",
    "        probabilities = self.predict_proba(X)\n",
    "        return (probabilities[:, 1] > 0.5).astype(int)\n",
    "\n",
    "# Create and test meta-learning ensemble\n",
    "print(\"\\nCreating Meta-Learning Ensemble...\")\n",
    "\n",
    "# Create meta-learning ensemble\n",
    "meta_ensemble = MetaLearnerEnsemble(base_models, cv_folds=5)\n",
    "\n",
    "# Train ensemble (this will take a bit longer due to cross-validation)\n",
    "meta_ensemble.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "meta_predictions = meta_ensemble.predict(X_test)\n",
    "meta_probabilities = meta_ensemble.predict_proba(X_test)\n",
    "\n",
    "# Evaluate performance\n",
    "meta_accuracy = accuracy_score(y_test, meta_predictions)\n",
    "meta_precision = precision_score(y_test, meta_predictions)\n",
    "meta_recall = recall_score(y_test, meta_predictions)\n",
    "meta_f1 = f1_score(y_test, meta_predictions)\n",
    "meta_roc_auc = roc_auc_score(y_test, meta_probabilities[:, 1])\n",
    "\n",
    "print(f\"\\nMeta-Learning Ensemble Performance:\")\n",
    "print(f\"Accuracy: {meta_accuracy:.4f}\")\n",
    "print(f\"Precision: {meta_precision:.4f}\")\n",
    "print(f\"Recall: {meta_recall:.4f}\")\n",
    "print(f\"F1-Score: {meta_f1:.4f}\")\n",
    "print(f\"ROC-AUC: {meta_roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Dynamic Model Selection\n",
    "\n",
    "### Instance-Based Model Selection\n",
    "\n",
    "Instead of using all models for every prediction, we can:\n",
    "1. **Evaluate model confidence** for each prediction\n",
    "2. **Select best-performing models** for each instance\n",
    "3. **Weight by confidence** or performance\n",
    "4. **Use diversity measures** to avoid similar models\n",
    "\n",
    "### Selection Strategies\n",
    "\n",
    "- **Performance-based**: Choose models with highest validation accuracy\n",
    "- **Confidence-based**: Weight models by prediction confidence\n",
    "- **Diversity-based**: Select diverse models to avoid correlation\n",
    "- **Hybrid**: Combine multiple selection criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DynamicEnsembleSelector:\n",
    "    \"\"\"\n",
    "    Dynamic ensemble that selects optimal models for each prediction.\n",
    "    \n",
    "    Key features:\n",
    "    - Instance-based model selection\n",
    "    - Multiple selection strategies\n",
    "    - Confidence-weighted predictions\n",
    "    - Performance-based ranking\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, base_models, selection_strategy='performance', top_k=3):\n",
    "        \"\"\"\n",
    "        Initialize dynamic ensemble selector.\n",
    "        \n",
    "        Args:\n",
    "            base_models: Dictionary of base models\n",
    "            selection_strategy: Strategy for model selection ('performance', 'confidence', 'diversity')\n",
    "            top_k: Number of top models to select\n",
    "        \"\"\"\n",
    "        self.base_models = base_models\n",
    "        self.selection_strategy = selection_strategy\n",
    "        self.top_k = min(top_k, len(base_models))\n",
    "        self.model_names = list(base_models.keys())\n",
    "        self.n_models = len(base_models)\n",
    "        \n",
    "        # Performance tracking\n",
    "        self.model_performance = {}\n",
    "        self.model_confidence = {}\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit the dynamic ensemble selector.\n",
    "        \n",
    "        Args:\n",
    "            X: Training features\n",
    "            y: Training labels\n",
    "        \"\"\"\n",
    "        print(\"Training dynamic ensemble selector...\")\n",
    "        \n",
    "        # Train base models\n",
    "        for name, model in self.base_models.items():\n",
    "            print(f\"  Training {name}...\")\n",
    "            model.fit(X, y)\n",
    "        \n",
    "        # Evaluate model performance using cross-validation\n",
    "        print(\"  Evaluating model performance...\")\n",
    "        self._evaluate_model_performance(X, y)\n",
    "        \n",
    "        print(f\"  Dynamic selector trained with {self.n_models} models\")\n",
    "        print(f\"  Selection strategy: {self.selection_strategy}\")\n",
    "        print(f\"  Top-k models: {self.top_k}\")\n",
    "    \n",
    "    def _evaluate_model_performance(self, X, y):\n",
    "        \"\"\"\n",
    "        Evaluate model performance using cross-validation.\n",
    "        \n",
    "        Args:\n",
    "            X: Training features\n",
    "            y: Training labels\n",
    "        \"\"\"\n",
    "        skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        \n",
    "        # Initialize performance tracking\n",
    "        for name in self.model_names:\n",
    "            self.model_performance[name] = []\n",
    "            self.model_confidence[name] = []\n",
    "        \n",
    "        # Cross-validation evaluation\n",
    "        for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "            # Get fold data\n",
    "            if isinstance(X, pd.DataFrame):\n",
    "                X_fold_train, X_fold_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "            else:\n",
    "                X_fold_train, X_fold_val = X[train_idx], X[val_idx]\n",
    "            \n",
    "            y_fold_train = y.iloc[train_idx] if isinstance(y, pd.Series) else y[train_idx]\n",
    "            y_fold_val = y.iloc[val_idx] if isinstance(y, pd.Series) else y[val_idx]\n",
    "            \n",
    "            # Evaluate each model\n",
    "            for name, model in self.base_models.items():\n",
    "                # Clone and train model on fold\n",
    "                from sklearn.base import clone\n",
    "                fold_model = clone(model)\n",
    "                fold_model.fit(X_fold_train, y_fold_train)\n",
    "                \n",
    "                # Predict on validation set\n",
    "                if hasattr(fold_model, 'predict_proba'):\n",
    "                    y_prob = fold_model.predict_proba(X_fold_val)[:, 1]\n",
    "                else:\n",
    "                    decisions = fold_model.decision_function(X_fold_val)\n",
    "                    y_prob = 1 / (1 + np.exp(-decisions))\n",
    "                \n",
    "                y_pred = (y_prob > 0.5).astype(int)\n",
    "                \n",
    "                # Calculate performance metrics\n",
    "                f1 = f1_score(y_fold_val, y_pred)\n",
    "                self.model_performance[name].append(f1)\n",
    "                \n",
    "                # Calculate confidence (inverse of prediction uncertainty)\n",
    "                confidence = np.mean(np.abs(y_prob - 0.5)) * 2  # Scale to 0-1\n",
    "                self.model_confidence[name].append(confidence)\n",
    "        \n",
    "        # Average performance across folds\n",
    "        for name in self.model_names:\n",
    "            self.model_performance[name] = np.mean(self.model_performance[name])\n",
    "            self.model_confidence[name] = np.mean(self.model_confidence[name])\n",
    "    \n",
    "    def _select_models_for_instance(self, instance_predictions):\n",
    "        \"\"\"\n",
    "        Select optimal models for a single instance.\n",
    "        \n",
    "        Args:\n",
    "            instance_predictions: Predictions for a single instance\n",
    "        \n",
    "        Returns:\n",
    "            Selected model indices and weights\n",
    "        \"\"\"\n",
    "        if self.selection_strategy == 'performance':\n",
    "            # Select top-k models based on cross-validation performance\n",
    "            performance_scores = [self.model_performance[name] for name in self.model_names]\n",
    "            selected_indices = np.argsort(performance_scores)[-self.top_k:]\n",
    "            weights = np.array([performance_scores[i] for i in selected_indices])\n",
    "            weights = weights / np.sum(weights)\n",
    "            \n",
    "        elif self.selection_strategy == 'confidence':\n",
    "            # Select models with highest confidence for this instance\n",
    "            confidences = [np.abs(instance_predictions[i] - 0.5) * 2 for i in range(len(instance_predictions))]\n",
    "            selected_indices = np.argsort(confidences)[-self.top_k:]\n",
    "            weights = np.array([confidences[i] for i in selected_indices])\n",
    "            weights = weights / np.sum(weights) if np.sum(weights) > 0 else np.ones(len(weights)) / len(weights)\n",
    "            \n",
    "        elif self.selection_strategy == 'diversity':\n",
    "            # Select diverse models (different predictions)\n",
    "            # Simple diversity measure: variance of predictions\n",
    "            selected_indices = []\n",
    "            remaining_indices = list(range(len(instance_predictions)))\n",
    "            \n",
    "            # Start with best performing model\n",
    "            performance_scores = [self.model_performance[name] for name in self.model_names]\n",
    "            best_idx = np.argmax(performance_scores)\n",
    "            selected_indices.append(best_idx)\n",
    "            remaining_indices.remove(best_idx)\n",
    "            \n",
    "            # Add models that maximize diversity\n",
    "            for _ in range(self.top_k - 1):\n",
    "                if not remaining_indices:\n",
    "                    break\n",
    "                \n",
    "                best_diversity = -1\n",
    "                best_candidate = None\n",
    "                \n",
    "                for candidate in remaining_indices:\n",
    "                    # Calculate diversity with selected models\n",
    "                    candidate_preds = [instance_predictions[i] for i in selected_indices + [candidate]]\n",
    "                    diversity = np.var(candidate_preds)\n",
    "                    \n",
    "                    if diversity > best_diversity:\n",
    "                        best_diversity = diversity\n",
    "                        best_candidate = candidate\n",
    "                \n",
    "                if best_candidate is not None:\n",
    "                    selected_indices.append(best_candidate)\n",
    "                    remaining_indices.remove(best_candidate)\n",
    "            \n",
    "            # Equal weights for diversity\n",
    "            weights = np.ones(len(selected_indices)) / len(selected_indices)\n",
    "            \n",
    "        else:\n",
    "            # Default: use all models with equal weights\n",
    "            selected_indices = list(range(len(instance_predictions)))\n",
    "            weights = np.ones(len(selected_indices)) / len(selected_indices)\n",
    "        \n",
    "        return selected_indices, weights\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        Make predictions using dynamic model selection.\n",
    "        \n",
    "        Args:\n",
    "            X: Features\n",
    "        \n",
    "        Returns:\n",
    "            Prediction probabilities\n",
    "        \"\"\"\n",
    "        # Get predictions from all base models\n",
    "        all_predictions = np.zeros((len(X), self.n_models))\n",
    "        \n",
    "        for i, (name, model) in enumerate(self.base_models.items()):\n",
    "            if hasattr(model, 'predict_proba'):\n",
    "                all_predictions[:, i] = model.predict_proba(X)[:, 1]\n",
    "            else:\n",
    "                decisions = model.decision_function(X)\n",
    "                all_predictions[:, i] = 1 / (1 + np.exp(-decisions))\n",
    "        \n",
    "        # Dynamic selection for each instance\n",
    "        ensemble_predictions = np.zeros(len(X))\n",
    "        \n",
    "        for i in range(len(X)):\n",
    "            instance_predictions = all_predictions[i]\n",
    "            selected_indices, weights = self._select_models_for_instance(instance_predictions)\n",
    "            \n",
    "            # Weighted prediction\n",
    "            selected_predictions = instance_predictions[selected_indices]\n",
    "            ensemble_predictions[i] = np.dot(selected_predictions, weights)\n",
    "        \n",
    "        # Convert to probability format\n",
    "        prob_positive = ensemble_predictions\n",
    "        prob_negative = 1 - prob_positive\n",
    "        \n",
    "        return np.column_stack([prob_negative, prob_positive])\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Make binary predictions.\"\"\"\n",
    "        probabilities = self.predict_proba(X)\n",
    "        return (probabilities[:, 1] > 0.5).astype(int)\n",
    "    \n",
    "    def get_model_ranking(self):\n",
    "        \"\"\"\n",
    "        Get model performance ranking.\n",
    "        \n",
    "        Returns:\n",
    "            Sorted list of models by performance\n",
    "        \"\"\"\n",
    "        performance_items = [(name, perf) for name, perf in self.model_performance.items()]\n",
    "        return sorted(performance_items, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Create and test dynamic selector\n",
    "print(\"\\nCreating Dynamic Ensemble Selector...\")\n",
    "\n",
    "# Create dynamic selector\n",
    "dynamic_selector = DynamicEnsembleSelector(base_models, selection_strategy='performance', top_k=3)\n",
    "\n",
    "# Train selector\n",
    "dynamic_selector.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "dynamic_predictions = dynamic_selector.predict(X_test)\n",
    "dynamic_probabilities = dynamic_selector.predict_proba(X_test)\n",
    "\n",
    "# Evaluate performance\n",
    "dynamic_accuracy = accuracy_score(y_test, dynamic_predictions)\n",
    "dynamic_precision = precision_score(y_test, dynamic_predictions)\n",
    "dynamic_recall = recall_score(y_test, dynamic_predictions)\n",
    "dynamic_f1 = f1_score(y_test, dynamic_predictions)\n",
    "dynamic_roc_auc = roc_auc_score(y_test, dynamic_probabilities[:, 1])\n",
    "\n",
    "print(f\"\\nDynamic Ensemble Selector Performance:\")\n",
    "print(f\"Accuracy: {dynamic_accuracy:.4f}\")\n",
    "print(f\"Precision: {dynamic_precision:.4f}\")\n",
    "print(f\"Recall: {dynamic_recall:.4f}\")\n",
    "print(f\"F1-Score: {dynamic_f1:.4f}\")\n",
    "print(f\"ROC-AUC: {dynamic_roc_auc:.4f}\")\n",
    "\n",
    "# Show model ranking\n",
    "model_ranking = dynamic_selector.get_model_ranking()\n",
    "print(f\"\\nModel Performance Ranking:\")\n",
    "for i, (name, performance) in enumerate(model_ranking):\n",
    "    print(f\"  {i+1}. {name}: {performance:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Hybrid Ensemble System\n",
    "\n",
    "### Combining All Approaches\n",
    "\n",
    "The hybrid ensemble system combines all three approaches:\n",
    "1. **Context-Aware Ensemble**: Adapts to transaction characteristics\n",
    "2. **Meta-Learning Ensemble**: Learns optimal combination strategies\n",
    "3. **Dynamic Selector**: Chooses best models for each prediction\n",
    "4. **Final Meta-Ensemble**: Combines predictions from all three systems\n",
    "\n",
    "### Hierarchical Architecture\n",
    "\n",
    "```\n",
    "Base Models → Context-Aware Ensemble →\n",
    "             Meta-Learning Ensemble  → Final Meta-Ensemble → Prediction\n",
    "             Dynamic Selector       →\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridEnsembleSystem:\n",
    "    \"\"\"\n",
    "    Hybrid ensemble system combining multiple advanced ensemble techniques.\n",
    "    \n",
    "    Architecture:\n",
    "    - Context-aware ensemble\n",
    "    - Meta-learning ensemble\n",
    "    - Dynamic model selector\n",
    "    - Final meta-ensemble\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, base_models):\n",
    "        \"\"\"\n",
    "        Initialize hybrid ensemble system.\n",
    "        \n",
    "        Args:\n",
    "            base_models: Dictionary of base models\n",
    "        \"\"\"\n",
    "        self.base_models = base_models\n",
    "        \n",
    "        # Initialize ensemble components\n",
    "        self.context_ensemble = ContextAwareEnsemble(base_models, n_context_clusters=5)\n",
    "        self.meta_ensemble = MetaLearnerEnsemble(base_models, cv_folds=5)\n",
    "        self.dynamic_selector = DynamicEnsembleSelector(base_models, selection_strategy='performance', top_k=3)\n",
    "        \n",
    "        # Final meta-ensemble to combine all approaches\n",
    "        self.final_meta_ensemble = LogisticRegression(random_state=42, class_weight='balanced')\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit the hybrid ensemble system.\n",
    "        \n",
    "        Args:\n",
    "            X: Training features\n",
    "            y: Training labels\n",
    "        \"\"\"\n",
    "        print(\"Training Hybrid Ensemble System...\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        # Train all ensemble components\n",
    "        print(\"\\n1. Training Context-Aware Ensemble...\")\n",
    "        self.context_ensemble.fit(X, y)\n",
    "        \n",
    "        print(\"\\n2. Training Meta-Learning Ensemble...\")\n",
    "        self.meta_ensemble.fit(X, y)\n",
    "        \n",
    "        print(\"\\n3. Training Dynamic Selector...\")\n",
    "        self.dynamic_selector.fit(X, y)\n",
    "        \n",
    "        # Generate meta-features for final ensemble\n",
    "        print(\"\\n4. Generating final meta-features...\")\n",
    "        final_meta_features = self._generate_final_meta_features(X)\n",
    "        \n",
    "        # Train final meta-ensemble\n",
    "        print(\"\\n5. Training final meta-ensemble...\")\n",
    "        self.final_meta_ensemble.fit(final_meta_features, y)\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"Hybrid Ensemble System Training Complete!\")\n",
    "        print(\"=\"*50)\n",
    "    \n",
    "    def _generate_final_meta_features(self, X):\n",
    "        \"\"\"\n",
    "        Generate meta-features from all ensemble components.\n",
    "        \n",
    "        Args:\n",
    "            X: Features\n",
    "        \n",
    "        Returns:\n",
    "            Final meta-features\n",
    "        \"\"\"\n",
    "        # Get predictions from all ensemble components\n",
    "        context_probs = self.context_ensemble.predict_proba(X)[:, 1]\n",
    "        meta_probs = self.meta_ensemble.predict_proba(X)[:, 1]\n",
    "        dynamic_probs = self.dynamic_selector.predict_proba(X)[:, 1]\n",
    "        \n",
    "        # Engineer meta-features\n",
    "        features = []\n",
    "        \n",
    "        # Raw ensemble predictions\n",
    "        features.append(context_probs.reshape(-1, 1))\n",
    "        features.append(meta_probs.reshape(-1, 1))\n",
    "        features.append(dynamic_probs.reshape(-1, 1))\n",
    "        \n",
    "        # Statistical features\n",
    "        ensemble_preds = np.column_stack([context_probs, meta_probs, dynamic_probs])\n",
    "        features.append(np.mean(ensemble_preds, axis=1).reshape(-1, 1))\n",
    "        features.append(np.std(ensemble_preds, axis=1).reshape(-1, 1))\n",
    "        features.append(np.min(ensemble_preds, axis=1).reshape(-1, 1))\n",
    "        features.append(np.max(ensemble_preds, axis=1).reshape(-1, 1))\n",
    "        \n",
    "        # Agreement features\n",
    "        binary_preds = (ensemble_preds > 0.5).astype(int)\n",
    "        agreement = np.mean(binary_preds, axis=1).reshape(-1, 1)\n",
    "        features.append(agreement)\n",
    "        \n",
    "        # Disagreement features\n",
    "        disagreement = np.std(binary_preds, axis=1).reshape(-1, 1)\n",
    "        features.append(disagreement)\n",
    "        \n",
    "        # Pairwise differences\n",
    "        features.append((context_probs - meta_probs).reshape(-1, 1))\n",
    "        features.append((context_probs - dynamic_probs).reshape(-1, 1))\n",
    "        features.append((meta_probs - dynamic_probs).reshape(-1, 1))\n",
    "        \n",
    "        # Combine all features\n",
    "        final_features = np.hstack(features)\n",
    "        \n",
    "        return final_features\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        Make predictions using hybrid ensemble.\n",
    "        \n",
    "        Args:\n",
    "            X: Features\n",
    "        \n",
    "        Returns:\n",
    "            Prediction probabilities\n",
    "        \"\"\"\n",
    "        # Generate final meta-features\n",
    "        final_meta_features = self._generate_final_meta_features(X)\n",
    "        \n",
    "        # Make final prediction\n",
    "        final_prediction = self.final_meta_ensemble.predict_proba(final_meta_features)\n",
    "        \n",
    "        return final_prediction\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Make binary predictions.\"\"\"\n",
    "        probabilities = self.predict_proba(X)\n",
    "        return (probabilities[:, 1] > 0.5).astype(int)\n",
    "    \n",
    "    def get_detailed_predictions(self, X):\n",
    "        \"\"\"\n",
    "        Get predictions from all ensemble components.\n",
    "        \n",
    "        Args:\n",
    "            X: Features\n",
    "        \n",
    "        Returns:\n",
    "            Dictionary with predictions from all components\n",
    "        \"\"\"\n",
    "        context_probs = self.context_ensemble.predict_proba(X)[:, 1]\n",
    "        meta_probs = self.meta_ensemble.predict_proba(X)[:, 1]\n",
    "        dynamic_probs = self.dynamic_selector.predict_proba(X)[:, 1]\n",
    "        final_probs = self.predict_proba(X)[:, 1]\n",
    "        \n",
    "        return {\n",
    "            'context_aware': context_probs,\n",
    "            'meta_learning': meta_probs,\n",
    "            'dynamic_selector': dynamic_probs,\n",
    "            'final_ensemble': final_probs\n",
    "        }\n",
    "\n",
    "# Create and test hybrid ensemble system\n",
    "print(\"\\nCreating Hybrid Ensemble System...\")\n",
    "\n",
    "# Create hybrid ensemble\n",
    "hybrid_ensemble = HybridEnsembleSystem(base_models)\n",
    "\n",
    "# Train hybrid ensemble (this will take some time)\n",
    "hybrid_ensemble.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "hybrid_predictions = hybrid_ensemble.predict(X_test)\n",
    "hybrid_probabilities = hybrid_ensemble.predict_proba(X_test)\n",
    "\n",
    "# Evaluate performance\n",
    "hybrid_accuracy = accuracy_score(y_test, hybrid_predictions)\n",
    "hybrid_precision = precision_score(y_test, hybrid_predictions)\n",
    "hybrid_recall = recall_score(y_test, hybrid_predictions)\n",
    "hybrid_f1 = f1_score(y_test, hybrid_predictions)\n",
    "hybrid_roc_auc = roc_auc_score(y_test, hybrid_probabilities[:, 1])\n",
    "\n",
    "print(f\"\\nHybrid Ensemble System Performance:\")\n",
    "print(f\"Accuracy: {hybrid_accuracy:.4f}\")\n",
    "print(f\"Precision: {hybrid_precision:.4f}\")\n",
    "print(f\"Recall: {hybrid_recall:.4f}\")\n",
    "print(f\"F1-Score: {hybrid_f1:.4f}\")\n",
    "print(f\"ROC-AUC: {hybrid_roc_auc:.4f}\")\n",
    "\n",
    "# Get detailed predictions for analysis\n",
    "detailed_predictions = hybrid_ensemble.get_detailed_predictions(X_test)\n",
    "\n",
    "print(f\"\\nDetailed Predictions Analysis:\")\n",
    "for component, predictions in detailed_predictions.items():\n",
    "    component_binary = (predictions > 0.5).astype(int)\n",
    "    component_f1 = f1_score(y_test, component_binary)\n",
    "    component_auc = roc_auc_score(y_test, predictions)\n",
    "    print(f\"  {component}: F1={component_f1:.4f}, AUC={component_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Comprehensive Performance Comparison\n",
    "\n",
    "Let's compare all the ensemble approaches we've implemented:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive performance comparison\n",
    "def comprehensive_performance_comparison():\n",
    "    \"\"\"\n",
    "    Compare all ensemble approaches and visualize results.\n",
    "    \"\"\"\n",
    "    print(\"\\nComprehensive Performance Comparison\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Collect all results\n",
    "    results = {\n",
    "        'Context-Aware': {\n",
    "            'accuracy': context_accuracy,\n",
    "            'precision': context_precision,\n",
    "            'recall': context_recall,\n",
    "            'f1_score': context_f1,\n",
    "            'roc_auc': context_roc_auc,\n",
    "            'probabilities': context_probabilities[:, 1]\n",
    "        },\n",
    "        'Meta-Learning': {\n",
    "            'accuracy': meta_accuracy,\n",
    "            'precision': meta_precision,\n",
    "            'recall': meta_recall,\n",
    "            'f1_score': meta_f1,\n",
    "            'roc_auc': meta_roc_auc,\n",
    "            'probabilities': meta_probabilities[:, 1]\n",
    "        },\n",
    "        'Dynamic Selector': {\n",
    "            'accuracy': dynamic_accuracy,\n",
    "            'precision': dynamic_precision,\n",
    "            'recall': dynamic_recall,\n",
    "            'f1_score': dynamic_f1,\n",
    "            'roc_auc': dynamic_roc_auc,\n",
    "            'probabilities': dynamic_probabilities[:, 1]\n",
    "        },\n",
    "        'Hybrid Ensemble': {\n",
    "            'accuracy': hybrid_accuracy,\n",
    "            'precision': hybrid_precision,\n",
    "            'recall': hybrid_recall,\n",
    "            'f1_score': hybrid_f1,\n",
    "            'roc_auc': hybrid_roc_auc,\n",
    "            'probabilities': hybrid_probabilities[:, 1]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Create comparison table\n",
    "    comparison_data = []\n",
    "    for method, metrics in results.items():\n",
    "        comparison_data.append({\n",
    "            'Method': method,\n",
    "            'Accuracy': f\"{metrics['accuracy']:.4f}\",\n",
    "            'Precision': f\"{metrics['precision']:.4f}\",\n",
    "            'Recall': f\"{metrics['recall']:.4f}\",\n",
    "            'F1-Score': f\"{metrics['f1_score']:.4f}\",\n",
    "            'ROC-AUC': f\"{metrics['roc_auc']:.4f}\"\n",
    "        })\n",
    "    \n",
    "    comparison_df = pd.DataFrame(comparison_data)\n",
    "    print(comparison_df.to_string(index=False))\n",
    "    \n",
    "    # Visualize performance comparison\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    \n",
    "    # Performance metrics bar chart\n",
    "    metrics = ['accuracy', 'precision', 'recall', 'f1_score', 'roc_auc']\n",
    "    methods = list(results.keys())\n",
    "    \n",
    "    x = np.arange(len(methods))\n",
    "    width = 0.15\n",
    "    \n",
    "    for i, metric in enumerate(metrics):\n",
    "        values = [results[method][metric] for method in methods]\n",
    "        axes[0, 0].bar(x + i * width, values, width, label=metric.replace('_', ' ').title())\n",
    "    \n",
    "    axes[0, 0].set_xlabel('Ensemble Method')\n",
    "    axes[0, 0].set_ylabel('Score')\n",
    "    axes[0, 0].set_title('Performance Metrics Comparison')\n",
    "    axes[0, 0].set_xticks(x + width * 2)\n",
    "    axes[0, 0].set_xticklabels(methods, rotation=45, ha='right')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # ROC curves\n",
    "    for method, metrics in results.items():\n",
    "        fpr, tpr, _ = roc_curve(y_test, metrics['probabilities'])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        axes[0, 1].plot(fpr, tpr, linewidth=2, label=f'{method} (AUC = {roc_auc:.3f})')\n",
    "    \n",
    "    axes[0, 1].plot([0, 1], [0, 1], 'k--', linewidth=1)\n",
    "    axes[0, 1].set_xlabel('False Positive Rate')\n",
    "    axes[0, 1].set_ylabel('True Positive Rate')\n",
    "    axes[0, 1].set_title('ROC Curves Comparison')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # F1-Score comparison\n",
    "    f1_scores = [results[method]['f1_score'] for method in methods]\n",
    "    bars = axes[1, 0].bar(methods, f1_scores, color=['lightblue', 'lightgreen', 'lightcoral', 'gold'])\n",
    "    \n",
    "    # Highlight best performer\n",
    "    best_idx = np.argmax(f1_scores)\n",
    "    bars[best_idx].set_color('darkgreen')\n",
    "    \n",
    "    axes[1, 0].set_ylabel('F1-Score')\n",
    "    axes[1, 0].set_title('F1-Score Comparison')\n",
    "    axes[1, 0].set_ylim(0, 1)\n",
    "    \n",
    "    # Add value labels\n",
    "    for i, (method, score) in enumerate(zip(methods, f1_scores)):\n",
    "        axes[1, 0].text(i, score + 0.01, f'{score:.3f}', ha='center', va='bottom')\n",
    "    \n",
    "    plt.setp(axes[1, 0].get_xticklabels(), rotation=45, ha='right')\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Prediction correlation heatmap\n",
    "    correlation_data = {}\n",
    "    for method, metrics in results.items():\n",
    "        correlation_data[method] = metrics['probabilities']\n",
    "    \n",
    "    correlation_df = pd.DataFrame(correlation_data)\n",
    "    correlation_matrix = correlation_df.corr()\n",
    "    \n",
    "    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, \n",
    "                square=True, ax=axes[1, 1])\n",
    "    axes[1, 1].set_title('Prediction Correlation Matrix')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Find best performing method\n",
    "    best_method = max(results.keys(), key=lambda x: results[x]['f1_score'])\n",
    "    best_f1 = results[best_method]['f1_score']\n",
    "    \n",
    "    print(f\"\\nBest Performing Method: {best_method}\")\n",
    "    print(f\"Best F1-Score: {best_f1:.4f}\")\n",
    "    \n",
    "    # Calculate improvement over baseline\n",
    "    baseline_f1 = max(results[method]['f1_score'] for method in ['Context-Aware', 'Meta-Learning', 'Dynamic Selector'])\n",
    "    hybrid_f1 = results['Hybrid Ensemble']['f1_score']\n",
    "    \n",
    "    improvement = ((hybrid_f1 - baseline_f1) / baseline_f1) * 100\n",
    "    print(f\"\\nHybrid Ensemble Improvement: {improvement:.2f}% over best individual method\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run comprehensive comparison\n",
    "comparison_results = comprehensive_performance_comparison()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice Exercises\n",
    "\n",
    "Now it's your turn! Try these exercises to deepen your understanding:\n",
    "\n",
    "### Exercise 1: Custom Context Features\n",
    "Modify the `ContextAwareEnsemble` to use different context features:\n",
    "- Add seasonal features (month, quarter)\n",
    "- Include economic indicators (if available)\n",
    "- Try different clustering algorithms (DBSCAN, Hierarchical)\n",
    "\n",
    "How do these changes affect performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# Hint: Modify the _extract_context_features method\n",
    "# Try different context features and compare performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Meta-Feature Engineering\n",
    "Enhance the meta-learning ensemble with new features:\n",
    "- Add prediction confidence intervals\n",
    "- Include model uncertainty measures\n",
    "- Try different meta-learners (Neural Networks, SVM)\n",
    "\n",
    "Which meta-features are most important?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# Hint: Modify the _engineer_meta_features method\n",
    "# Add feature importance analysis for meta-learners"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Dynamic Selection Strategies\n",
    "Implement new selection strategies:\n",
    "- **Competence-based**: Select models based on local performance\n",
    "- **Clustering-based**: Use feature space clustering for selection\n",
    "- **Ensemble of selectors**: Combine multiple selection strategies\n",
    "\n",
    "Which strategy works best for your data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# Hint: Add new selection strategies to the DynamicEnsembleSelector\n",
    "# Compare different strategies on the same dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "### 1. Advanced Ensemble Strategies\n",
    "- **Context-Aware**: Adapt to transaction characteristics and patterns\n",
    "- **Meta-Learning**: Learn optimal combination strategies from data\n",
    "- **Dynamic Selection**: Choose best models for each prediction\n",
    "- **Hierarchical**: Multi-level ensemble architectures\n",
    "\n",
    "### 2. Meta-Learning Principles\n",
    "- **Cross-Validation**: Prevent overfitting in meta-feature generation\n",
    "- **Feature Engineering**: Create meaningful meta-features\n",
    "- **Multiple Meta-Learners**: Ensemble at the meta-level\n",
    "- **Stacking**: Layer models for optimal performance\n",
    "\n",
    "### 3. Context-Aware Systems\n",
    "- **Feature Extraction**: Time, amount, statistical measures\n",
    "- **Clustering**: Group similar transaction contexts\n",
    "- **Adaptive Weighting**: Learn context-specific model weights\n",
    "- **Dynamic Application**: Apply weights based on current context\n",
    "\n",
    "### 4. Dynamic Model Selection\n",
    "- **Instance-Based**: Choose models for each prediction\n",
    "- **Performance-Based**: Select top-performing models\n",
    "- **Confidence-Based**: Weight by prediction confidence\n",
    "- **Diversity-Based**: Ensure model diversity\n",
    "\n",
    "### 5. System Integration\n",
    "- **Modular Design**: Independent ensemble components\n",
    "- **Hierarchical Structure**: Multiple levels of ensembling\n",
    "- **Cross-Validation**: Proper validation throughout\n",
    "- **Final Meta-Ensemble**: Combine all approaches optimally\n",
    "\n",
    "### 6. Performance Optimization\n",
    "- **Complementary Strengths**: Different ensembles excel in different areas\n",
    "- **Reduced Variance**: Multiple approaches reduce overfitting\n",
    "- **Improved Generalization**: Better performance on unseen data\n",
    "- **Robustness**: Resilient to individual model failures\n",
    "\n",
    "### 7. Production Considerations\n",
    "- **Computational Cost**: Balance performance vs efficiency\n",
    "- **Model Interpretability**: Understand ensemble decisions\n",
    "- **Maintenance**: Update and retrain individual components\n",
    "- **Scalability**: Handle large-scale deployment\n",
    "\n",
    "### 8. When to Use Each Approach\n",
    "- **Context-Aware**: When transaction patterns vary by context\n",
    "- **Meta-Learning**: When you have sufficient training data\n",
    "- **Dynamic Selection**: When models have varying performance\n",
    "- **Hybrid**: When you need maximum performance\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "In the next tutorial, we'll explore:\n",
    "- Professional fraud detection dashboards\n",
    "- Real-time monitoring and alerting\n",
    "- Business intelligence and reporting\n",
    "- User interface design for fraud analysts\n",
    "\n",
    "Remember: Hybrid ensemble systems represent the state-of-the-art in machine learning. While they're complex to implement, they can provide significant performance improvements by combining the strengths of multiple approaches. The key is understanding when and how to apply each technique!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}