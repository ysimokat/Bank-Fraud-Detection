# üìö Credit Card Fraud Detection - Study Guide

## üéØ Learning Objectives

By completing this project, you will learn:
1. How to handle highly imbalanced datasets
2. Multiple machine learning and deep learning techniques
3. Production deployment with APIs and dashboards
4. Advanced concepts like graph neural networks and active learning

## üìñ Table of Contents

1. [Getting Started](#getting-started)
2. [Core Concepts](#core-concepts)
3. [Hands-On Exercises](#hands-on-exercises)
4. [Understanding the Models](#understanding-the-models)
5. [Advanced Topics](#advanced-topics)
6. [Project Workflow](#project-workflow)
7. [Best Practices](#best-practices)
8. [Resources](#resources)

## üöÄ Getting Started

### Step 1: Environment Setup
```bash
# Create and activate virtual environment
python -m venv venv
venv\Scripts\activate  # Windows
source venv/bin/activate  # Linux/Mac

# Install dependencies
pip install -r requirements.txt

# Test GPU setup (optional)
python gpu_config.py
```

### Step 2: Download Dataset
1. Visit [Kaggle Credit Card Fraud Dataset](https://www.kaggle.com/mlg-ulb/creditcardfraud)
2. Download `creditcard.csv`
3. Place in project root directory

### Step 3: First Run
```bash
# Quick test (10 minutes)
python integrated_fraud_pipeline.py --quick

# View results
python professional_fraud_dashboard.py
```

## üìä Core Concepts

### 1. Imbalanced Classification
- **Problem**: Only 0.172% of transactions are fraudulent
- **Solutions**: 
  - SMOTE (Synthetic Minority Over-sampling)
  - Class weights
  - Focal Loss
  - Cost-sensitive learning

### 2. Evaluation Metrics
- **F1-Score**: Harmonic mean of precision and recall
- **ROC-AUC**: Area under the receiver operating characteristic curve
- **Precision**: True positives / (True positives + False positives)
- **Recall**: True positives / (True positives + False negatives)

### 3. Feature Engineering
- PCA features (V1-V28) are already transformed
- Time and Amount are original features
- Create interaction features
- Statistical aggregations

## üèãÔ∏è Hands-On Exercises

### Exercise 1: Basic Models (Beginner)
```python
# Run basic models
python fraud_detection_models.py

# Questions to answer:
# 1. Which model performs best?
# 2. What are the top 5 important features?
# 3. How many false positives vs false negatives?
```

### Exercise 2: Deep Learning (Intermediate)
```python
# Run deep learning models
python enhanced_deep_learning.py

# Tasks:
# 1. Compare Focal Loss vs Weighted BCE
# 2. Analyze autoencoder reconstruction errors
# 3. Experiment with different architectures
```

### Exercise 3: Graph Neural Networks (Advanced)
```python
# Run GNN model
python graph_neural_network.py

# Explore:
# 1. How are transaction relationships defined?
# 2. What patterns do GNNs detect that others miss?
# 3. Visualize the transaction graph
```

### Exercise 4: Production Deployment
```python
# Start API server
python enhanced_fraud_api.py

# Test with curl or Python requests
# 1. Make single predictions
# 2. Test batch predictions
# 3. Measure latency
```

## üß† Understanding the Models

### Traditional ML Models

#### Random Forest
```python
# Key hyperparameters
n_estimators=100      # Number of trees
max_depth=None        # Tree depth
class_weight='balanced'  # Handle imbalance
```
**When it works well**: Non-linear patterns, feature interactions

#### XGBoost
```python
# Key hyperparameters
learning_rate=0.1     # Step size
n_estimators=100      # Boosting rounds
scale_pos_weight=ratio  # Handle imbalance
```
**When it works well**: Complex patterns, handles missing data

### Deep Learning Models

#### Focal Loss
```python
# Addresses class imbalance by focusing on hard examples
focal_loss = -Œ±(1-pt)^Œ≥ * log(pt)
# Œ±: class weight, Œ≥: focusing parameter
```
**Use case**: Extreme class imbalance

#### Autoencoder
```python
# Learns to reconstruct normal transactions
# High reconstruction error = potential fraud
encoder: input ‚Üí compressed ‚Üí latent
decoder: latent ‚Üí decompressed ‚Üí output
```
**Use case**: Anomaly detection without labels

### Graph Neural Networks
```python
# Analyzes relationships between transactions
nodes = transactions
edges = shared_features (card, merchant, time)
```
**Use case**: Detecting fraud rings, coordinated attacks

## üî¨ Advanced Topics

### 1. Online Learning
- Process transactions in real-time
- Update models incrementally
- Detect concept drift

### 2. Active Learning
- Identify uncertain predictions
- Query human experts efficiently
- Continuously improve model

### 3. Meta-Learning Ensemble
- Learn when each model performs best
- Dynamic model selection
- Context-aware predictions

### 4. Model Calibration
- Ensure prediction probabilities are accurate
- Important for risk-based decisions
- Isotonic regression, Platt scaling

## üîÑ Project Workflow

### Phase 1: Data Understanding
```bash
# Explore data
cd tutorials
jupyter notebook
# Open data_exploration.ipynb
```

### Phase 2: Model Development
```bash
# Train all models
python integrated_fraud_pipeline.py
```

### Phase 3: Evaluation
```bash
# Compare models
python professional_fraud_dashboard.py
```

### Phase 4: Advanced Models
```bash
# Include all advanced systems
python advanced_integrated_pipeline.py
```

### Phase 5: Deployment
```bash
# API server
python enhanced_fraud_api.py

# Monitor performance
# Check http://localhost:8000/metrics
```

## ‚úÖ Best Practices

### 1. Data Handling
- Always use stratified splits
- Don't leak information from test set
- Handle missing values appropriately

### 2. Model Training
- Use cross-validation
- Monitor for overfitting
- Save intermediate results

### 3. Evaluation
- Use multiple metrics
- Consider business impact
- Test on recent data

### 4. Production
- Monitor model drift
- Log predictions
- Have fallback strategies

## üìö Learning Resources

### Tutorials (in order)
1. `data_exploration.ipynb` - Understand the data
2. `fraud_detection_models.ipynb` - Basic ML models
3. `enhanced_fraud_models.ipynb` - Advanced ML
4. `enhanced_deep_learning.ipynb` - Deep learning
5. `heterogeneous_gnn.ipynb` - Graph networks
6. `online_streaming_system.ipynb` - Real-time systems
7. `hybrid_ensemble_system.ipynb` - Ensemble methods
8. `professional_fraud_dashboard.ipynb` - Dashboards
9. `enhanced_fraud_api.ipynb` - API development
10. `advanced_model_calibration.ipynb` - Calibration

### Key Papers to Read
1. "SMOTE: Synthetic Minority Over-sampling Technique"
2. "Focal Loss for Dense Object Detection"
3. "Graph Neural Networks: A Review"
4. "Learning under Concept Drift"

### Online Courses
1. Fast.ai - Practical Deep Learning
2. Coursera - Machine Learning by Andrew Ng
3. Graph Neural Networks course by Stanford

## üéØ Learning Milestones

### Week 1: Foundations
- [ ] Run basic pipeline
- [ ] Understand evaluation metrics
- [ ] Complete first 3 tutorials

### Week 2: Advanced Models
- [ ] Implement custom feature engineering
- [ ] Train deep learning models
- [ ] Understand ensemble methods

### Week 3: Production Skills
- [ ] Deploy API
- [ ] Create custom dashboard
- [ ] Implement monitoring

### Week 4: Research
- [ ] Read papers on fraud detection
- [ ] Implement new technique
- [ ] Share findings

## üí° Tips for Success

1. **Start Simple**: Use `--quick` mode first
2. **Read Output**: The pipeline explains what it's doing
3. **Experiment**: Try different hyperparameters
4. **Document**: Keep notes on what works
5. **Ask Questions**: Use GitHub issues for help

## üèÜ Challenge Projects

### Beginner
1. Add a new evaluation metric
2. Create custom visualizations
3. Implement stratified k-fold CV

### Intermediate
1. Design new features
2. Implement a new model
3. Create model explanations

### Advanced
1. Implement federated learning
2. Add adversarial training
3. Create real-time monitoring system

## üìù Final Project Ideas

1. **Custom Fraud Detector**: Implement your own algorithm
2. **Explainable AI**: Create interpretable models
3. **Mobile App**: Deploy model to mobile
4. **Research Paper**: Document novel findings

---

Remember: The goal is not just to run the code, but to understand the concepts and be able to apply them to new problems. Happy learning!